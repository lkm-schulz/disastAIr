{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DIR_DATA = os.path.join(\"..\", \"data\")\n",
    "PATH_DATA_TRAIN = os.path.join(DIR_DATA, \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start: 0, end: 1523, total_len: 7613\n",
      "start: 1523, end: 3045, total_len: 7613\n",
      "start: 3045, end: 4568, total_len: 7613\n",
      "start: 4568, end: 6090, total_len: 7613\n",
      "start: 6090, end: 7613, total_len: 7613\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(PATH_DATA_TRAIN)\n",
    "\n",
    "NUM_SETS = 5\n",
    "\n",
    "len_chunk = len(df_train) / NUM_SETS\n",
    "\n",
    "train_sets = [None] * NUM_SETS\n",
    "val_sets = [None] * NUM_SETS\n",
    "\n",
    "df_shuffled = df_train.sample(frac=1)\n",
    "\n",
    "for i in range(5):\n",
    "    start = round(i * len_chunk)\n",
    "    end = round((i + 1) * len_chunk)\n",
    "    print(f'start: {start}, end: {end}, total_len: {len(df_train)}')\n",
    "    val_sets[i] = df_train.iloc[start:end,:]\n",
    "    train_sets[i] = df_train[~df_train.index.isin(val_sets[i].index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKOV_ORDER = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import sys\n",
    "\n",
    "SMOOTHING_WEIGHT = 1\n",
    "NUM_CHARS = 95\n",
    "\n",
    "class MarkovModel:\n",
    "    order: int\n",
    "    ngram_freqs: list[dict]\n",
    "    totals: list[int]\n",
    "\n",
    "    def __init__(self, order: int, sequences: list[str] = []):\n",
    "        assert(order >= 0)\n",
    "\n",
    "        self.order = order\n",
    "        self.ngram_freqs = [defaultdict(int)] * (order + 1)\n",
    "        self.totals = [0] * (order + 1)\n",
    "\n",
    "        if (len(sequences) > 0):\n",
    "            i = 0\n",
    "            for seq in sequences:\n",
    "                i += 1\n",
    "                print(f'Processing sequence {i:>{math.floor(math.log(len(sequences), 10)) + 1}}/{len(sequences)} for {order} orders', end='\\r')\n",
    "                for n in range(0, order + 1):\n",
    "                    for pos in range(len(seq) - n):\n",
    "                        ngram = seq[pos:pos+n+1]\n",
    "                        self.add_ngram_occurrence(ngram)\n",
    "            print()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.order}-Order Markov NGram Object - Totals: {self.totals}'\n",
    "    \n",
    "    def __check_len(self, l):\n",
    "        if l > self.order + 1 or l == 0:\n",
    "            raise ValueError(f'Invalid NGram - Length of ngram must be between 1 and {self.order + 1} for an order {self.order} NGrams object (is {l})')\n",
    "\n",
    "    def add_ngram_occurrence(self, ngram : str):\n",
    "        self.__check_len(len(ngram))\n",
    "        self.ngram_freqs[len(ngram) - 1][ngram] += 1\n",
    "        self.totals[len(ngram) - 1] += 1\n",
    "\n",
    "    def get_total_occurrences(self, ngram : str):\n",
    "        self.__check_len(len(ngram))\n",
    "        return self.ngram_freqs[len(ngram) - 1][ngram]\n",
    "    \n",
    "    def get_log_cond_prob(self, ngram : str):\n",
    "        self.__check_len(len(ngram))\n",
    "\n",
    "        top = self.get_total_occurrences(ngram) + SMOOTHING_WEIGHT\n",
    "        bot = self.totals[0] if (len(ngram) == 1) else self.get_total_occurrences(ngram[:-1])\n",
    "        bot += SMOOTHING_WEIGHT * ((len(ngram) - 1) ** NUM_CHARS)\n",
    "        \n",
    "        return math.log(top / bot) if top > 0 else sys.minint\n",
    "    \n",
    "    def get_log_sum_prob(self, seq : str):\n",
    "        if (len(seq) == 0):\n",
    "            raise ValueError(f'Invalid Sequence - Cannot get probability for an empty string')\n",
    "\n",
    "        start = 0\n",
    "        end = 1\n",
    "        sum = 0\n",
    "\n",
    "        while (end <= len(seq)):\n",
    "            sum += self.get_log_cond_prob(seq[start:end])\n",
    "            end += 1\n",
    "\n",
    "            # ngrams can be at most order + 1 characters long:\n",
    "            if (end - start > self.order + 1):\n",
    "                start += 1\n",
    "\n",
    "        return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sequence 3271/3271 for 5 orders\n",
      "Processing sequence 4342/4342 for 5 orders\n"
     ]
    }
   ],
   "source": [
    "texts_pos = (df_train.loc[df_train['target'] == 1])['text'].to_list()\n",
    "texts_neg = (df_train.loc[df_train['target'] == 0])['text'].to_list()\n",
    "\n",
    "texts_lower_pos = map(lambda string: string.lower(), texts_pos)\n",
    "texts_lower_neg = map(lambda string: string.lower(), texts_neg)\n",
    "\n",
    "model_pos = MarkovModel(MARKOV_ORDER, texts_pos)\n",
    "model_neg = MarkovModel(MARKOV_ORDER, texts_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "44\n",
      "277\n",
      "2204\n",
      "-131.69796430638962\n",
      "-127.86932290990052\n",
      "-126.78530942065356\n",
      "-96.53655014711781\n"
     ]
    }
   ],
   "source": [
    "print(model_neg.get_total_occurrences('hello'))\n",
    "print(model_neg.get_total_occurrences('today'))\n",
    "print(model_neg.get_total_occurrences('https'))\n",
    "print(model_neg.get_total_occurrences('http'))\n",
    "print(model_pos.get_log_cond_prob('hello'))\n",
    "print(model_pos.get_log_cond_prob('today'))\n",
    "print(model_pos.get_log_cond_prob('https'))\n",
    "print(model_pos.get_log_cond_prob('http'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence is likely not about a real disaster. ('They should all die! All of them! Everything annihilated!')\n",
      "The sentence is likely not about a real disaster. ('@sakuma_en If you pretend to feel a certain way the feeling can become genuine all by accident. -Hei (Darker than Black) #manga #anime')\n",
      "The sentence is likely about a real disaster. ('Shot 12 times. Found dead in cuffs after being involved in a car accident. Officers told ambulance not to treat him. https://t.co/MEUDJwaaNg')\n",
      "The sentence is likely not about a real disaster. ('@NinaHoag - 'if you shred my Psych work our friendship would be annihilated')\n",
      "The sentence is likely about a real disaster. ('Why should a helicopter ambulance ride to transfer to a hospital 21 miles away cost $29800?')\n",
      "The sentence is likely not about a real disaster. ('If you build an army of 100 lions and their leader is a dog in any fight the lions will die like a dog.')\n",
      "The sentence is likely not about a real disaster. ('One Direction Is my pick for http://t.co/q2eBlOKeVE Fan Army #Directioners http://t.co/eNCmhz6y34 x1424')\n"
     ]
    }
   ],
   "source": [
    "def predict(sequence: str):\n",
    "    pos = model_pos.get_log_sum_prob(sequence)\n",
    "    neg = model_neg.get_log_sum_prob(sequence)\n",
    "\n",
    "    print(f'The sentence is likely ', end='')\n",
    "    if (pos < neg):\n",
    "        print('not ', end='')\n",
    "    print(f'about a real disaster. (\\'{sequence}\\')')\n",
    "    \n",
    "predict(\"They should all die! All of them! Everything annihilated!\")\n",
    "predict(\"@sakuma_en If you pretend to feel a certain way the feeling can become genuine all by accident. -Hei (Darker than Black) #manga #anime\")\n",
    "predict(\"Shot 12 times. Found dead in cuffs after being involved in a car accident. Officers told ambulance not to treat him. https://t.co/MEUDJwaaNg\")\n",
    "predict(\"@NinaHoag - 'if you shred my Psych work our friendship would be annihilated\")\n",
    "predict(\"Why should a helicopter ambulance ride to transfer to a hospital 21 miles away cost $29800?\")\n",
    "predict(\"If you build an army of 100 lions and their leader is a dog in any fight the lions will die like a dog.\")\n",
    "predict(\"One Direction Is my pick for http://t.co/q2eBlOKeVE Fan Army #Directioners http://t.co/eNCmhz6y34 x1424\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[] only ascii chars?\n",
    "[] remove links?\n",
    "[] keep or remove hashtags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
