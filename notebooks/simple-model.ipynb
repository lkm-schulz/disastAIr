{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DIR_DATA = os.path.join(\"..\", \"data\")\n",
    "PATH_DATA_TRAIN = os.path.join(DIR_DATA, \"train.csv\")\n",
    "PATH_DATA_TEST = os.path.join(DIR_DATA, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(PATH_DATA_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crossval_sets(df: pd.DataFrame, num_sets: int):\n",
    "\n",
    "    df_shuffled: pd.DataFrame = df.sample(frac=1)\n",
    "    len_chunk = len(df) / num_sets\n",
    "\n",
    "    sets = {}\n",
    "    sets['train'] = [None] * num_sets\n",
    "    sets['val'] = [None] * num_sets\n",
    "\n",
    "    for i in range(num_sets):\n",
    "        start = round(i * len_chunk)\n",
    "        end = round((i + 1) * len_chunk)\n",
    "        sets['val'][i] = df_shuffled.iloc[start:end,:]\n",
    "        sets['train'][i] = df_shuffled[~df_shuffled.index.isin(sets['val'][i].index)]\n",
    "\n",
    "    return sets\n",
    "\n",
    "def get_instances(df: pd.DataFrame, target: int):\n",
    "    return list(map(lambda string: string, (df.loc[df['target'] == target])['text'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "from multiprocessing import Pool, Manager, Process\n",
    "import multiprocessing\n",
    "from markov_helper import count_ngrams, progress_monitor\n",
    "\n",
    "MARKOV_SMOOTHING_WEIGHT = 1\n",
    "MARKOV_NUM_CHARS = 95\n",
    "MARKOV_MULTITHREAD_NUM_WORKERS = multiprocessing.cpu_count()\n",
    "\n",
    "class MarkovModel:\n",
    "    order: int\n",
    "    ngram_freqs: list[dict]\n",
    "    totals: list[int]\n",
    "    __pool = Pool(processes=MARKOV_MULTITHREAD_NUM_WORKERS)\n",
    "    __manager = Manager()\n",
    "\n",
    "    def __init__(self, order: int, sequences: list[str] = [], multithread: bool = True, verbose: bool = False):\n",
    "        assert(order >= 0)\n",
    "\n",
    "        self.order = order\n",
    "        self.ngram_freqs = [defaultdict(int)] * (order + 1)\n",
    "        self.totals = [0] * (order + 1)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        if (multithread):\n",
    "            processes = [None] * (order + 1)  \n",
    "            progresses = [None] * (order + 1)\n",
    "\n",
    "            try:\n",
    "                for n in range(order + 1):\n",
    "                    progresses[n] = MarkovModel.__manager.Value('i', 0)\n",
    "                    process = MarkovModel.__pool.apply_async(count_ngrams, args=(sequences, n, progresses[n]))\n",
    "                    processes[n] = process   \n",
    "\n",
    "                if verbose:\n",
    "                    monitor = Process(target=progress_monitor, args=(progresses, order + 1, len(sequences)))\n",
    "                    monitor.start()\n",
    "                \n",
    "                for n in range(len(processes)):\n",
    "                    (total, frequencies) = processes[n].get()\n",
    "                    self.totals[n] = total\n",
    "                    self.ngram_freqs[n] = frequencies\n",
    "                \n",
    "            except Exception as e:\n",
    "                MarkovModel.__pool.terminate()\n",
    "                MarkovModel.__pool = Pool(processes=MARKOV_MULTITHREAD_NUM_WORKERS)\n",
    "                raise e\n",
    "            finally:\n",
    "                if verbose:\n",
    "                    monitor.terminate()\n",
    "                \n",
    "        else:\n",
    "            if (len(sequences) > 0):\n",
    "                i = 0\n",
    "                for seq in sequences:\n",
    "                    i += 1\n",
    "                    print(f'Processing sequence {i:>{math.floor(math.log(len(sequences), 10)) + 1}}/{len(sequences)} for {order} orders', end='\\r')\n",
    "                    for n in range(0, order + 1):\n",
    "                        for pos in range(len(seq) - n):\n",
    "                            ngram = seq[pos:pos+n+1]\n",
    "                            self.add_ngram_occurrence(ngram)\n",
    "\n",
    "        duration = time.time() - start\n",
    "        if verbose:\n",
    "            print(f'Order {order} Markov Model of {len(sequences)} sequences built in {duration:.3f} seconds!')\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.order}-Order Markov NGram Object - Totals: {self.totals}'\n",
    "    \n",
    "    def __check_len(self, l):\n",
    "        if l > self.order + 1 or l == 0:\n",
    "            raise ValueError(f'Invalid NGram - Length of ngram must be between 1 and {self.order + 1} for an order {self.order} NGrams object (is {l})')\n",
    "\n",
    "    def add_ngram_occurrence(self, ngram : str):\n",
    "        self.__check_len(len(ngram))\n",
    "        self.ngram_freqs[len(ngram) - 1][ngram] += 1\n",
    "        self.totals[len(ngram) - 1] += 1\n",
    "\n",
    "    def get_total_occurrences(self, ngram : str):\n",
    "        self.__check_len(len(ngram))\n",
    "        return self.ngram_freqs[len(ngram) - 1][ngram]\n",
    "    \n",
    "    def get_log_cond_prob(self, ngram : str):\n",
    "        self.__check_len(len(ngram))\n",
    "\n",
    "        top = self.get_total_occurrences(ngram) + MARKOV_SMOOTHING_WEIGHT\n",
    "        bot = self.totals[0] if (len(ngram) == 1) else self.get_total_occurrences(ngram[:-1])\n",
    "        bot += MARKOV_SMOOTHING_WEIGHT * ((len(ngram) - 1) ** MARKOV_NUM_CHARS)\n",
    "        \n",
    "        return math.log(top / bot) if top > 0 else sys.minint\n",
    "    \n",
    "    def get_log_sum_prob(self, seq: str):\n",
    "        if (len(seq) == 0):\n",
    "            raise ValueError(f'Invalid Sequence - Cannot get probability for an empty string')\n",
    "\n",
    "        start = 0\n",
    "        end = 1\n",
    "        sum = 0\n",
    "\n",
    "        while (end <= len(seq)):\n",
    "            sum += self.get_log_cond_prob(seq[start:end])\n",
    "            end += 1\n",
    "\n",
    "            # ngrams can be at most order + 1 characters long:\n",
    "            if (end - start > self.order + 1):\n",
    "                start += 1\n",
    "        return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order 0 Markov Model of 3271 sequences built in 0.130 seconds!\n",
      "Order 0 Markov Model of 4342 sequences built in 0.125 seconds!\n",
      "Positives match: True, Negatives match: True\n",
      "Positives match: True, Negatives match: True\n",
      "Positives match: True, Negatives match: True\n",
      "Positives match: True, Negatives match: True\n",
      "Positives match: True, Negatives match: True\n",
      "Positives match: True, Negatives match: True\n",
      "Positives match: True, Negatives match: True\n"
     ]
    }
   ],
   "source": [
    "texts_pos = (df_train.loc[df_train['target'] == 1])['text'].to_list()\n",
    "texts_neg = (df_train.loc[df_train['target'] == 0])['text'].to_list()\n",
    "\n",
    "MARKOV_ORDER = 10\n",
    "\n",
    "model_pos = MarkovModel(MARKOV_ORDER, texts_pos, verbose=True)\n",
    "model_neg = MarkovModel(MARKOV_ORDER, texts_neg, verbose=True)\n",
    "model_pos2 = MarkovModel(MARKOV_ORDER, texts_pos, False)\n",
    "model_neg2 = MarkovModel(MARKOV_ORDER, texts_neg, False)\n",
    "\n",
    "def compare(sequence: str):\n",
    "    pos1 = model_pos.get_log_sum_prob(sequence)\n",
    "    pos2 = model_pos2.get_log_sum_prob(sequence)\n",
    "    neg1 = model_neg.get_log_sum_prob(sequence)\n",
    "    neg2 = model_neg2.get_log_sum_prob(sequence)\n",
    "\n",
    "    print(f'Positives match: {pos1 == pos2}, Negatives match: {neg1 == neg2}')\n",
    "\n",
    "compare(\"They should all die! All of them! Everything annihilated!\")\n",
    "compare(\"@sakuma_en If you pretend to feel a certain way the feeling can become genuine all by accident. -Hei (Darker than Black) #manga #anime\")\n",
    "compare(\"Shot 12 times. Found dead in cuffs after being involved in a car accident. Officers told ambulance not to treat him. https://t.co/MEUDJwaaNg\")\n",
    "compare(\"@NinaHoag - 'if you shred my Psych work our friendship would be annihilated\")\n",
    "compare(\"Why should a helicopter ambulance ride to transfer to a hospital 21 miles away cost $29800?\")\n",
    "compare(\"If you build an army of 100 lions and their leader is a dog in any fight the lions will die like a dog.\")\n",
    "compare(\"One Direction Is my pick for http://t.co/q2eBlOKeVE Fan Army #Directioners http://t.co/eNCmhz6y34 x1424\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos: -13.811853220094644, neg: -13.953968805082148\n",
      "The sentence is likely about a real disaster. ('scam')\n",
      "pos: -196.60674640987213, neg: -192.5929563419966\n",
      "The sentence is likely not about a real disaster. ('They should all die! All of them! Everything annihilated!')\n",
      "pos: -448.44077156095744, neg: -444.15605884872247\n",
      "The sentence is likely not about a real disaster. ('@sakuma_en If you pretend to feel a certain way the feeling can become genuine all by accident. -Hei (Darker than Black) #manga #anime')\n",
      "pos: -463.04862129203457, neg: -465.4699402086199\n",
      "The sentence is likely about a real disaster. ('Shot 12 times. Found dead in cuffs after being involved in a car accident. Officers told ambulance not to treat him. https://t.co/MEUDJwaaN')\n",
      "pos: -254.8816003269804, neg: -252.53742721732874\n",
      "The sentence is likely not about a real disaster. ('@NinaHoag - 'if you shred my Psych work our friendship would be annihilated')\n",
      "pos: -309.5961458163629, neg: -309.2896992697805\n",
      "The sentence is likely not about a real disaster. ('Why should a helicopter ambulance ride to transfer to a hospital 21 miles away cost $29800?')\n",
      "pos: -325.01456479842693, neg: -323.4805772631018\n",
      "The sentence is likely not about a real disaster. ('If you build an army of 100 lions and their leader is a dog in any fight the lions will die like a dog.')\n",
      "pos: -393.48085644221516, neg: -398.1367077480627\n",
      "The sentence is likely about a real disaster. ('One Direction Is my pick for http://t.co/q2eBlOKeVE Fan Army #Directioners http://t.co/eNCmhz6y34 x1424')\n"
     ]
    }
   ],
   "source": [
    "def predict(sequence: str):\n",
    "    pos = model_pos.get_log_sum_prob(sequence)\n",
    "    neg = model_neg.get_log_sum_prob(sequence)\n",
    "    print(f'pos: {pos}, neg: {neg}')\n",
    "    print(f'The sentence is likely ', end='')\n",
    "    if (pos < neg):\n",
    "        print('not ', end='')\n",
    "    print(f'about a real disaster. (\\'{sequence}\\')')\n",
    "\n",
    "predict(\"They should all die! All of them! Everything annihilated!\")\n",
    "predict(\"@sakuma_en If you pretend to feel a certain way the feeling can become genuine all by accident. -Hei (Darker than Black) #manga #anime\")\n",
    "predict(\"Shot 12 times. Found dead in cuffs after being involved in a car accident. Officers told ambulance not to treat him. https://t.co/MEUDJwaaN\")\n",
    "predict(\"@NinaHoag - 'if you shred my Psych work our friendship would be annihilated\")\n",
    "predict(\"Why should a helicopter ambulance ride to transfer to a hospital 21 miles away cost $29800?\")\n",
    "predict(\"If you build an army of 100 lions and their leader is a dog in any fight the lions will die like a dog.\")\n",
    "predict(\"One Direction Is my pick for http://t.co/q2eBlOKeVE Fan Army #Directioners http://t.co/eNCmhz6y34 x1424\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    tp: int\n",
    "    fp: int\n",
    "    tn: int\n",
    "    fn: int\n",
    "\n",
    "    def __init__(self, tp: int = 0, tn: int = 0, fp: int = 0, fn: int = 0):\n",
    "        self.tp = tp\n",
    "        self.fp = fp\n",
    "        self.tn = tn\n",
    "        self.fn = fn\n",
    "\n",
    "    def __str__(self):\n",
    "        total = self.tp + self.fp + self.tn + self.fn\n",
    "        return f'Total: {total:.1f}, TP: {self.tp:.1f}, TN: {self.tn:.1f}, FP: {self.fp:.1f}, FN: {self.fn:.1f}, Prc: {self.get_precision():.3f}, Rec. {self.get_recall():.3f}, F1: {self.get_f1():.3f}'\n",
    "    \n",
    "    def get_f1(self):\n",
    "        return 2 * ((self.get_precision() * self.get_recall()) / (self.get_precision() + self.get_recall()))\n",
    "    \n",
    "    def get_precision(self):\n",
    "        return self.tp / (self.tp + self.fp)\n",
    "\n",
    "    def get_recall(self):\n",
    "        return self.tp / (self.tp + self.fn) \n",
    "\n",
    "    def add(self, rhs: 'ConfusionMatrix'):\n",
    "        self.tp += rhs.tp\n",
    "        self.fp += rhs.fp\n",
    "        self.tn += rhs.tn\n",
    "        self.fn += rhs.fn\n",
    "\n",
    "    def div(self, divisor):\n",
    "        self.tp /= divisor\n",
    "        self.fp /= divisor\n",
    "        self.tn /= divisor\n",
    "        self.fn /= divisor\n",
    "\n",
    "    @classmethod\n",
    "    def average(cls, matrices: list['ConfusionMatrix']):\n",
    "        result = ConfusionMatrix()\n",
    "        for cm in matrices:\n",
    "            result.add(cm)\n",
    "        result.div(len(matrices))\n",
    "\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovClassifier:\n",
    "    model_pos: MarkovModel\n",
    "    model_neg: MarkovModel\n",
    "    order: int\n",
    "\n",
    "    def __init__(self, order: int, positives: list[str], negatives: list[str], verbose: bool = False):\n",
    "        self.model_pos = MarkovModel(order, positives, multithread=True, verbose=verbose)\n",
    "        self.model_neg = MarkovModel(order, negatives, multithread=True, verbose=verbose)\n",
    "        self.order = order\n",
    "\n",
    "    def classify(self, seq: str) -> bool:\n",
    "        return self.model_pos.get_log_sum_prob(seq) > self.model_neg.get_log_sum_prob(seq)\n",
    "\n",
    "    def eval(self, positives: list[str], negatives: list[str]) -> ConfusionMatrix:\n",
    "\n",
    "        res = ConfusionMatrix()\n",
    "\n",
    "        for instance in positives:\n",
    "            if self.classify(instance):\n",
    "                res.tp += 1\n",
    "            else:\n",
    "                res.fn += 1\n",
    "\n",
    "        for instance in negatives:\n",
    "            if not self.classify(instance):\n",
    "                res.tn += 1\n",
    "            else:\n",
    "                res.fp += 1\n",
    "        \n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order 0 results: Total: 1522.6, TP: 446.8, TN: 543.0, FP: 325.4, FN: 207.4, Prc: 0.579, Rec. 0.683, F1: 0.626\n",
      "Training: [Tot.: 0.406s, Avg.: 0.081s], Validation: [Tot.: 0.776s, Avg.: 0.155s]\n",
      "Order 1 results: Total: 1522.6, TP: 456.8, TN: 624.4, FP: 244.0, FN: 197.4, Prc: 0.652, Rec. 0.698, F1: 0.674\n",
      "Training: [Tot.: 0.516s, Avg.: 0.103s], Validation: [Tot.: 1.080s, Avg.: 0.216s]\n",
      "Order 2 results: Total: 1522.6, TP: 304.0, TN: 837.4, FP: 31.0, FN: 350.2, Prc: 0.907, Rec. 0.465, F1: 0.615\n",
      "Training: [Tot.: 0.659s, Avg.: 0.132s], Validation: [Tot.: 1.478s, Avg.: 0.296s]\n",
      "Order 3 results: Total: 1522.6, TP: 389.2, TN: 808.8, FP: 59.6, FN: 265.0, Prc: 0.867, Rec. 0.595, F1: 0.706\n",
      "Training: [Tot.: 0.795s, Avg.: 0.159s], Validation: [Tot.: 1.679s, Avg.: 0.336s]\n",
      "Order 4 results: Total: 1522.6, TP: 421.8, TN: 791.2, FP: 77.2, FN: 232.4, Prc: 0.845, Rec. 0.645, F1: 0.732\n",
      "Training: [Tot.: 0.992s, Avg.: 0.198s], Validation: [Tot.: 1.881s, Avg.: 0.376s]\n",
      "Order 5 results: Total: 1522.6, TP: 436.0, TN: 770.4, FP: 98.0, FN: 218.2, Prc: 0.816, Rec. 0.666, F1: 0.734\n",
      "Training: [Tot.: 1.297s, Avg.: 0.259s], Validation: [Tot.: 2.074s, Avg.: 0.415s]\n",
      "Order 6 results: Total: 1522.6, TP: 449.2, TN: 749.2, FP: 119.2, FN: 205.0, Prc: 0.790, Rec. 0.687, F1: 0.735\n",
      "Training: [Tot.: 1.428s, Avg.: 0.286s], Validation: [Tot.: 2.146s, Avg.: 0.429s]\n",
      "Order 7 results: Total: 1522.6, TP: 460.2, TN: 727.8, FP: 140.6, FN: 194.0, Prc: 0.766, Rec. 0.703, F1: 0.733\n",
      "Training: [Tot.: 1.703s, Avg.: 0.341s], Validation: [Tot.: 2.081s, Avg.: 0.416s]\n",
      "Order 8 results: Total: 1522.6, TP: 467.4, TN: 704.6, FP: 163.8, FN: 186.8, Prc: 0.740, Rec. 0.714, F1: 0.727\n",
      "Training: [Tot.: 2.063s, Avg.: 0.413s], Validation: [Tot.: 2.184s, Avg.: 0.437s]\n",
      "Order 9 results: Total: 1522.6, TP: 468.0, TN: 683.8, FP: 184.6, FN: 186.2, Prc: 0.717, Rec. 0.715, F1: 0.716\n",
      "Training: [Tot.: 2.507s, Avg.: 0.501s], Validation: [Tot.: 2.294s, Avg.: 0.459s]\n",
      "Order 10 results: Total: 1522.6, TP: 466.4, TN: 670.8, FP: 197.6, FN: 187.8, Prc: 0.702, Rec. 0.713, F1: 0.708\n",
      "Training: [Tot.: 3.305s, Avg.: 0.661s], Validation: [Tot.: 2.459s, Avg.: 0.492s]\n",
      "Order 11 results: Total: 1522.6, TP: 462.0, TN: 667.4, FP: 201.0, FN: 192.2, Prc: 0.697, Rec. 0.706, F1: 0.701\n",
      "Training: [Tot.: 3.602s, Avg.: 0.720s], Validation: [Tot.: 2.463s, Avg.: 0.493s]\n",
      "Order 12 results: Total: 1522.6, TP: 455.0, TN: 661.4, FP: 207.0, FN: 199.2, Prc: 0.687, Rec. 0.696, F1: 0.691\n",
      "Training: [Tot.: 3.747s, Avg.: 0.749s], Validation: [Tot.: 2.455s, Avg.: 0.491s]\n",
      "Order 13 results: Total: 1522.6, TP: 446.2, TN: 657.8, FP: 210.6, FN: 208.0, Prc: 0.679, Rec. 0.682, F1: 0.681\n",
      "Training: [Tot.: 3.963s, Avg.: 0.793s], Validation: [Tot.: 2.386s, Avg.: 0.477s]\n",
      "Order 14 results: Total: 1522.6, TP: 439.6, TN: 656.0, FP: 212.4, FN: 214.6, Prc: 0.674, Rec. 0.672, F1: 0.673\n",
      "Training: [Tot.: 4.266s, Avg.: 0.853s], Validation: [Tot.: 2.394s, Avg.: 0.479s]\n"
     ]
    }
   ],
   "source": [
    "NUM_SETS = 5\n",
    "\n",
    "sets = get_crossval_sets(df_train, NUM_SETS)\n",
    "\n",
    "for order in range(0, 15):\n",
    "    res = ConfusionMatrix()\n",
    "    time_training = 0.0\n",
    "    time_validation = 0.0\n",
    "\n",
    "    for i in range(NUM_SETS):\n",
    "        start = time.time()\n",
    "        classifier = MarkovClassifier(order, get_instances(sets['train'][i], 1), get_instances(sets['train'][i], 0))\n",
    "        time_training += time.time() - start\n",
    "        start = time.time()\n",
    "        cm = classifier.eval(get_instances(sets['val'][i], 1), get_instances(sets['val'][i], 0))\n",
    "        time_validation += time.time() - start\n",
    "        res.add(cm)\n",
    "\n",
    "    res.div(len(sets['train']))\n",
    "    print(f'Order {order} results: ', end='')\n",
    "    print(res)\n",
    "    print(f'Training: [Tot.: {time_training:5.3f}s, Avg.: {time_training / NUM_SETS:5.3f}s], Validation: [Tot.: {time_validation:5.3f}s, Avg.: {time_validation / NUM_SETS:5.3f}s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         0     NaN      NaN   \n",
       "1         2     NaN      NaN   \n",
       "2         3     NaN      NaN   \n",
       "3         9     NaN      NaN   \n",
       "4        11     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0                    Just happened a terrible car crash       1  \n",
       "1     Heard about #earthquake is different cities, s...       1  \n",
       "2     there is a forest fire at spot pond, geese are...       1  \n",
       "3              Apocalypse lighting. #Spokane #wildfires       1  \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan       1  \n",
       "...                                                 ...     ...  \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...       0  \n",
       "3259  Storm in RI worse than last hurricane. My city...       1  \n",
       "3260  Green Line derailment in Chicago http://t.co/U...       1  \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...       1  \n",
       "3262  #CityofCalgary has activated its Municipal Eme...       1  \n",
       "\n",
       "[3263 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = pd.read_csv(PATH_DATA_TEST)\n",
    "\n",
    "classifier = MarkovClassifier(6, get_instances(df_train, 1), get_instances(df_train, 0))\n",
    "df_test['target'] = df_test['text'].apply(classifier.classify).astype(int)\n",
    "\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       0\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_submission = df_test[['id', 'target']]\n",
    "display(df_submission)\n",
    "df_submission.to_csv(os.path.join(DIR_DATA, 'submission.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
