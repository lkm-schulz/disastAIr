{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DIR_DATA = os.path.join(\"..\", \"data\")\n",
    "PATH_DATA_TRAIN = os.path.join(DIR_DATA, \"train.csv\")\n",
    "PATH_DATA_TEST = os.path.join(DIR_DATA, \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(PATH_DATA_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "from multiprocessing import Pool, Manager, Process\n",
    "import multiprocessing\n",
    "from markov_helper import count_ngrams, progress_monitor\n",
    "\n",
    "MARKOV_DEF_SMOOTHING_WEIGHT = .1\n",
    "MARKOV_DEF_VOCAB_SIZE = 95\n",
    "MARKOV_MULTITHREAD_NUM_WORKERS = multiprocessing.cpu_count() - 2\n",
    "\n",
    "class MarkovModel:\n",
    "    order: int\n",
    "    ngram_freqs: list[dict]\n",
    "    totals: list[int]\n",
    "    vocab_size: int\n",
    "    smoothing_weight: float\n",
    "    __pool = Pool(processes=MARKOV_MULTITHREAD_NUM_WORKERS)\n",
    "    __manager = Manager()\n",
    "    __type = None\n",
    "\n",
    "    def __init__(self, order: int, sequences: list = [], multithread: bool = True, verbose: bool = False, \n",
    "                 vocab_size: int = MARKOV_DEF_VOCAB_SIZE, smoothing_weight: float = MARKOV_DEF_SMOOTHING_WEIGHT):\n",
    "        assert(order >= 0)\n",
    "\n",
    "        self.order = order\n",
    "        self.ngram_freqs = [defaultdict(int)] * (order + 1)\n",
    "        self.totals = [0] * (order + 1)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.smoothing_weight = smoothing_weight\n",
    "\n",
    "        if (len(sequences) > 0):\n",
    "            if isinstance(sequences[0], str):\n",
    "                self.__type = str\n",
    "            elif isinstance(sequences[0], list):\n",
    "                self.__type = list\n",
    "            else:\n",
    "                raise TypeError(f'sequences argument must be either a list of strings or list of lists (is list[{type(sequences[0])}]).')\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            if (multithread):\n",
    "                processes = [None] * (order + 1)  \n",
    "                progresses = [None] * (order + 1)\n",
    "\n",
    "                try:\n",
    "                    for n in range(order + 1):\n",
    "                        progresses[n] = MarkovModel.__manager.Value('i', 0)\n",
    "                        process = MarkovModel.__pool.apply_async(count_ngrams, args=(sequences, n, progresses[n]))\n",
    "                        processes[n] = process   \n",
    "\n",
    "                    if verbose:\n",
    "                        monitor = Process(target=progress_monitor, args=(progresses, order + 1, len(sequences)))\n",
    "                        monitor.start()\n",
    "                    \n",
    "                    for n in range(len(processes)):\n",
    "                        (total, frequencies) = processes[n].get()\n",
    "                        self.totals[n] = total\n",
    "                        self.ngram_freqs[n] = frequencies\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    MarkovModel.__pool.terminate()\n",
    "                    MarkovModel.__pool = Pool(processes=MARKOV_MULTITHREAD_NUM_WORKERS)\n",
    "                    raise e\n",
    "                finally:\n",
    "                    if verbose:\n",
    "                        monitor.terminate()\n",
    "                    \n",
    "            else:\n",
    "                i = 0\n",
    "                for seq in sequences:\n",
    "                    i += 1\n",
    "                    if i % 10 == 0:\n",
    "                        print(f'Counting NGrams for Markov Model: {(i / len(sequences) * 100):>5.2f}%', end='\\r')\n",
    "                    for n in range(0, order + 1):\n",
    "                        for pos in range(len(seq) - n):\n",
    "                            ngram = seq[pos:pos+n+1]\n",
    "                            self.add_ngram_occurrence(ngram)\n",
    "\n",
    "            duration = time.time() - start\n",
    "            if verbose:\n",
    "                print(f'Order {order} Markov Model of {len(sequences)} sequences built in {duration:.3f} seconds!')\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.order}-Order Markov NGram Object - Totals: {self.totals}'\n",
    "    \n",
    "    def __check_len(self, l):\n",
    "        if l > self.order + 1 or l == 0:\n",
    "            raise ValueError(f'Invalid NGram - Length of ngram must be between 1 and {self.order + 1} for an order {self.order} NGrams object (is {l})')\n",
    "\n",
    "    @classmethod\n",
    "    def __tuple_from_list(cls, l: list):\n",
    "        t = (l[0],)\n",
    "        for item in l[1:]:\n",
    "            t += (item,)\n",
    "\n",
    "        return t\n",
    "    \n",
    "    def __check_type(self, a):\n",
    "        if not isinstance(a, self.__type):\n",
    "            raise TypeError(f'Argument must be of type {self.__type} (is {type(a)})')\n",
    "\n",
    "    def add_ngram_occurrence(self, ngram):\n",
    "        self.__check_len(len(ngram))\n",
    "        self.__check_type(ngram)\n",
    "        self.ngram_freqs[len(ngram) - 1][MarkovModel.__tuple_from_list(ngram)] += 1\n",
    "        self.totals[len(ngram) - 1] += 1\n",
    "\n",
    "    def get_total_occurrences(self, ngram):\n",
    "        self.__check_len(len(ngram))\n",
    "        self.__check_type(ngram)\n",
    "        return self.ngram_freqs[len(ngram) - 1][MarkovModel.__tuple_from_list(ngram)]\n",
    "    \n",
    "    def get_log_cond_prob(self, ngram):\n",
    "        self.__check_len(len(ngram))\n",
    "        self.__check_type(ngram)\n",
    "\n",
    "        top = self.get_total_occurrences(ngram) + self.smoothing_weight\n",
    "        bot = self.totals[0] if (len(ngram) == 1) else self.get_total_occurrences(ngram[:-1])\n",
    "        bot += self.smoothing_weight * ((len(ngram) - 1) ** self.vocab_size)\n",
    "        \n",
    "        return math.log(top / bot) if top > 0 else sys.minint\n",
    "    \n",
    "    def get_log_sum_prob(self, seq: str):\n",
    "        # TODO: how to handle empty sequences (high or low value?)\n",
    "        # if (len(seq) == 0):\n",
    "        #     raise ValueError(f'Invalid Sequence - Cannot get probability for an empty list')\n",
    "\n",
    "        start = 0\n",
    "        end = 1\n",
    "        sum = 0\n",
    "\n",
    "        while (end <= len(seq)):\n",
    "            sum += self.get_log_cond_prob(seq[start:end])\n",
    "            end += 1\n",
    "\n",
    "            # ngrams can be at most order + 1 characters long:\n",
    "            if (end - start > self.order + 1):\n",
    "                start += 1\n",
    "        return sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order 10 Markov Model of 3271 sequences built in 0.567 seconds!\n",
      "Order 10 Markov Model of 4342 sequences built in 0.667 seconds!\n",
      "Order 10 Markov Model of 3271 sequences built in 2.957 seconds!\n",
      "Order 10 Markov Model of 4342 sequences built in 3.560 seconds!\n",
      "Positives match: True, Negatives match: True\n",
      "Positives match: True, Negatives match: True\n",
      "Positives match: True, Negatives match: True\n",
      "Positives match: True, Negatives match: True\n",
      "Positives match: True, Negatives match: True\n",
      "Positives match: True, Negatives match: True\n",
      "Positives match: True, Negatives match: True\n"
     ]
    }
   ],
   "source": [
    "texts_pos = (df_train.loc[df_train['target'] == 1])['text'].to_list()\n",
    "texts_neg = (df_train.loc[df_train['target'] == 0])['text'].to_list()\n",
    "\n",
    "MARKOV_ORDER = 10\n",
    "\n",
    "model_pos = MarkovModel(MARKOV_ORDER, texts_pos, verbose=True)\n",
    "model_neg = MarkovModel(MARKOV_ORDER, texts_neg, verbose=True)\n",
    "model_pos2 = MarkovModel(MARKOV_ORDER, texts_pos, multithread=False, verbose=True)\n",
    "model_neg2 = MarkovModel(MARKOV_ORDER, texts_neg, multithread=False, verbose=True)\n",
    "\n",
    "def compare(sequence: str):\n",
    "    pos1 = model_pos.get_log_sum_prob(sequence)\n",
    "    pos2 = model_pos2.get_log_sum_prob(sequence)\n",
    "    neg1 = model_neg.get_log_sum_prob(sequence)\n",
    "    neg2 = model_neg2.get_log_sum_prob(sequence)\n",
    "\n",
    "    print(f'Positives match: {pos1 == pos2}, Negatives match: {neg1 == neg2}')\n",
    "\n",
    "compare(\"They should all die! All of them! Everything annihilated!\")\n",
    "compare(\"@sakuma_en If you pretend to feel a certain way the feeling can become genuine all by accident. -Hei (Darker than Black) #manga #anime\")\n",
    "compare(\"Shot 12 times. Found dead in cuffs after being involved in a car accident. Officers told ambulance not to treat him. https://t.co/MEUDJwaaNg\")\n",
    "compare(\"@NinaHoag - 'if you shred my Psych work our friendship would be annihilated\")\n",
    "compare(\"Why should a helicopter ambulance ride to transfer to a hospital 21 miles away cost $29800?\")\n",
    "compare(\"If you build an army of 100 lions and their leader is a dog in any fight the lions will die like a dog.\")\n",
    "compare(\"One Direction Is my pick for http://t.co/q2eBlOKeVE Fan Army #Directioners http://t.co/eNCmhz6y34 x1424\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    tp: int\n",
    "    fp: int\n",
    "    tn: int\n",
    "    fn: int\n",
    "\n",
    "    def __init__(self, tp: int = 0, tn: int = 0, fp: int = 0, fn: int = 0):\n",
    "        self.tp = tp\n",
    "        self.fp = fp\n",
    "        self.tn = tn\n",
    "        self.fn = fn\n",
    "\n",
    "    def __str__(self):\n",
    "        total = self.tp + self.fp + self.tn + self.fn\n",
    "        return f'Total: {total:.1f}, TP: {self.tp:.1f}, TN: {self.tn:.1f}, FP: {self.fp:.1f}, FN: {self.fn:.1f}, Prc: {self.get_precision():.3f}, Rec. {self.get_recall():.3f}, F1: {self.get_f1():.3f}'\n",
    "    \n",
    "    def get_f1(self):\n",
    "        return 2 * ((self.get_precision() * self.get_recall()) / (self.get_precision() + self.get_recall()))\n",
    "    \n",
    "    def get_precision(self):\n",
    "        return self.tp / (self.tp + self.fp)\n",
    "\n",
    "    def get_recall(self):\n",
    "        return self.tp / (self.tp + self.fn) \n",
    "\n",
    "    def add(self, rhs: 'ConfusionMatrix'):\n",
    "        self.tp += rhs.tp\n",
    "        self.fp += rhs.fp\n",
    "        self.tn += rhs.tn\n",
    "        self.fn += rhs.fn\n",
    "\n",
    "    def div(self, divisor):\n",
    "        self.tp /= divisor\n",
    "        self.fp /= divisor\n",
    "        self.tn /= divisor\n",
    "        self.fn /= divisor\n",
    "\n",
    "    @classmethod\n",
    "    def average(cls, matrices: list['ConfusionMatrix']):\n",
    "        result = ConfusionMatrix()\n",
    "        for cm in matrices:\n",
    "            result.add(cm)\n",
    "        result.div(len(matrices))\n",
    "\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovClassifier:\n",
    "    model_pos: MarkovModel\n",
    "    model_neg: MarkovModel\n",
    "    order: int\n",
    "\n",
    "    def __init__(self, order: int, positives: list, negatives: list, verbose: bool = False, \n",
    "                 vocab_size: int = MARKOV_DEF_VOCAB_SIZE, smoothing_weight: float = MARKOV_DEF_SMOOTHING_WEIGHT):\n",
    "        \n",
    "        self.model_pos = MarkovModel(order, positives, multithread=True, verbose=verbose, vocab_size=vocab_size, smoothing_weight=smoothing_weight)\n",
    "        self.model_neg = MarkovModel(order, negatives, multithread=True, verbose=verbose, vocab_size=vocab_size, smoothing_weight=smoothing_weight)\n",
    "        self.order = order\n",
    "\n",
    "    def predict(self, seq) -> bool:\n",
    "        return self.model_pos.get_log_sum_prob(seq) > self.model_neg.get_log_sum_prob(seq)\n",
    "\n",
    "    def eval(self, positives: list, negatives: list) -> ConfusionMatrix:\n",
    "\n",
    "        res = ConfusionMatrix()\n",
    "\n",
    "        for instance in positives:\n",
    "            if self.predict(instance):\n",
    "                res.tp += 1\n",
    "            else:\n",
    "                res.fn += 1\n",
    "\n",
    "        for instance in negatives:\n",
    "            if not self.predict(instance):\n",
    "                res.tn += 1\n",
    "            else:\n",
    "                res.fp += 1\n",
    "        \n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "def get_crossval_sets(df: pd.DataFrame, num_sets: int):\n",
    "\n",
    "    df_shuffled: pd.DataFrame = df.sample(frac=1)\n",
    "    len_chunk = len(df) / num_sets\n",
    "\n",
    "    sets = {}\n",
    "    sets['train'] = [None] * num_sets\n",
    "    sets['val'] = [None] * num_sets\n",
    "\n",
    "    for i in range(num_sets):\n",
    "        start = round(i * len_chunk)\n",
    "        end = round((i + 1) * len_chunk)\n",
    "        sets['val'][i] = df_shuffled.iloc[start:end,:]\n",
    "        sets['train'][i] = df_shuffled[~df_shuffled.index.isin(sets['val'][i].index)]\n",
    "\n",
    "    return sets\n",
    "\n",
    "def get_wordlist(text: str) -> list[str]:\n",
    "    cleaned = text.lower()\n",
    "    cleaned = re.sub(r'https?:\\/\\/.*[\\r\\n]*|[^\\w\\s]', ' ', cleaned)\n",
    "    return cleaned.split()\n",
    "\n",
    "def get_instances(df: pd.DataFrame, target: int, mapping = lambda x: x):\n",
    "    return list(map(mapping, (df.loc[df['target'] == target])['text'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_orders(df: pd.DataFrame, num_sets: int = 5, mapping = lambda x: x, order_min: int = 0, order_max: int = 15, \n",
    "                print_results: bool = False, vocab_size: int = MARKOV_DEF_VOCAB_SIZE, smoothing_weight: float = MARKOV_DEF_SMOOTHING_WEIGHT):\n",
    "\n",
    "    order_max += 1\n",
    "    sets = get_crossval_sets(df, num_sets)\n",
    "    f1_scores = [0] * (order_max - order_min)\n",
    "\n",
    "    for order in range(order_min, order_max):\n",
    "        res = ConfusionMatrix()\n",
    "        time_training = 0.0\n",
    "        time_validation = 0.0\n",
    "\n",
    "        for i in range(num_sets):\n",
    "            start = time.time()\n",
    "            classifier = MarkovClassifier(order, get_instances(sets['train'][i], 1, mapping), \n",
    "                                          get_instances(sets['train'][i], 0, mapping), \n",
    "                                          vocab_size=vocab_size, smoothing_weight=smoothing_weight)\n",
    "            \n",
    "            time_training += time.time() - start\n",
    "            start = time.time()\n",
    "            cm = classifier.eval(get_instances(sets['val'][i], 1, mapping), get_instances(sets['val'][i], 0, mapping))\n",
    "            \n",
    "            time_validation += time.time() - start\n",
    "            res.add(cm)\n",
    "\n",
    "        res.div(len(sets['train']))\n",
    "        f1_scores[order - order_min] = res.get_f1()\n",
    "\n",
    "        if print_results:\n",
    "            print(f'Order {order} results: ', end='')\n",
    "            print(res)\n",
    "            print(f'Training: [Tot.: {time_training:5.3f}s, Avg.: {time_training / num_sets:5.3f}s], Validation: [Tot.: {time_validation:5.3f}s, Avg.: {time_validation / num_sets:5.3f}s]')\n",
    "\n",
    "    max_f1_index = max((v, i) for i, v in enumerate(f1_scores))[1]\n",
    "    return (max_f1_index, f1_scores[max_f1_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order 0 results: Total: 1522.6, TP: 503.6, TN: 677.8, FP: 190.6, FN: 150.6, Prc: 0.725, Rec. 0.770, F1: 0.747\n",
      "Training: [Tot.: 0.528s, Avg.: 0.106s], Validation: [Tot.: 0.219s, Avg.: 0.044s]\n",
      "Order 1 results: Total: 1522.6, TP: 446.6, TN: 193.4, FP: 675.0, FN: 207.6, Prc: 0.398, Rec. 0.683, F1: 0.503\n",
      "Training: [Tot.: 0.650s, Avg.: 0.130s], Validation: [Tot.: 0.329s, Avg.: 0.066s]\n",
      "Order 2 results: Total: 1522.6, TP: 515.8, TN: 462.2, FP: 406.2, FN: 138.4, Prc: 0.559, Rec. 0.788, F1: 0.654\n",
      "Training: [Tot.: 0.749s, Avg.: 0.150s], Validation: [Tot.: 0.392s, Avg.: 0.078s]\n",
      "Order 3 results: Total: 1522.6, TP: 560.2, TN: 331.8, FP: 536.6, FN: 94.0, Prc: 0.511, Rec. 0.856, F1: 0.640\n",
      "Training: [Tot.: 0.871s, Avg.: 0.174s], Validation: [Tot.: 0.437s, Avg.: 0.087s]\n",
      "Order 4 results: Total: 1522.6, TP: 570.0, TN: 306.8, FP: 561.6, FN: 84.2, Prc: 0.504, Rec. 0.871, F1: 0.638\n",
      "Training: [Tot.: 0.901s, Avg.: 0.180s], Validation: [Tot.: 0.465s, Avg.: 0.093s]\n",
      "Order 5 results: Total: 1522.6, TP: 571.6, TN: 298.8, FP: 569.6, FN: 82.6, Prc: 0.501, Rec. 0.874, F1: 0.637\n",
      "Training: [Tot.: 1.111s, Avg.: 0.222s], Validation: [Tot.: 0.471s, Avg.: 0.094s]\n",
      "Order 6 results: Total: 1522.6, TP: 572.0, TN: 296.4, FP: 572.0, FN: 82.2, Prc: 0.500, Rec. 0.874, F1: 0.636\n",
      "Training: [Tot.: 1.220s, Avg.: 0.244s], Validation: [Tot.: 0.481s, Avg.: 0.096s]\n",
      "Best order word based: (0, 0.7469593592405814)\n",
      "Order 0 results: Total: 1522.6, TP: 445.6, TN: 546.0, FP: 322.4, FN: 208.6, Prc: 0.580, Rec. 0.681, F1: 0.627\n",
      "Training: [Tot.: 0.603s, Avg.: 0.121s], Validation: [Tot.: 1.119s, Avg.: 0.224s]\n",
      "Order 1 results: Total: 1522.6, TP: 455.4, TN: 615.2, FP: 253.2, FN: 198.8, Prc: 0.643, Rec. 0.696, F1: 0.668\n",
      "Training: [Tot.: 0.791s, Avg.: 0.158s], Validation: [Tot.: 1.773s, Avg.: 0.355s]\n",
      "Order 2 results: Total: 1522.6, TP: 299.8, TN: 839.4, FP: 29.0, FN: 354.4, Prc: 0.912, Rec. 0.458, F1: 0.610\n",
      "Training: [Tot.: 1.105s, Avg.: 0.221s], Validation: [Tot.: 2.242s, Avg.: 0.448s]\n",
      "Order 3 results: Total: 1522.6, TP: 388.0, TN: 811.2, FP: 57.2, FN: 266.2, Prc: 0.872, Rec. 0.593, F1: 0.706\n",
      "Training: [Tot.: 1.406s, Avg.: 0.281s], Validation: [Tot.: 2.621s, Avg.: 0.524s]\n",
      "Order 4 results: Total: 1522.6, TP: 419.0, TN: 792.2, FP: 76.2, FN: 235.2, Prc: 0.846, Rec. 0.640, F1: 0.729\n",
      "Training: [Tot.: 1.796s, Avg.: 0.359s], Validation: [Tot.: 2.984s, Avg.: 0.597s]\n",
      "Order 5 results: Total: 1522.6, TP: 434.8, TN: 770.4, FP: 98.0, FN: 219.4, Prc: 0.816, Rec. 0.665, F1: 0.733\n",
      "Training: [Tot.: 2.339s, Avg.: 0.468s], Validation: [Tot.: 3.387s, Avg.: 0.677s]\n",
      "Order 6 results: Total: 1522.6, TP: 449.0, TN: 752.6, FP: 115.8, FN: 205.2, Prc: 0.795, Rec. 0.686, F1: 0.737\n",
      "Training: [Tot.: 2.735s, Avg.: 0.547s], Validation: [Tot.: 3.576s, Avg.: 0.715s]\n",
      "Order 7 results: Total: 1522.6, TP: 457.4, TN: 731.2, FP: 137.2, FN: 196.8, Prc: 0.769, Rec. 0.699, F1: 0.733\n",
      "Training: [Tot.: 3.237s, Avg.: 0.647s], Validation: [Tot.: 3.694s, Avg.: 0.739s]\n",
      "Order 8 results: Total: 1522.6, TP: 465.4, TN: 706.2, FP: 162.2, FN: 188.8, Prc: 0.742, Rec. 0.711, F1: 0.726\n",
      "Training: [Tot.: 4.228s, Avg.: 0.846s], Validation: [Tot.: 3.868s, Avg.: 0.774s]\n",
      "Order 9 results: Total: 1522.6, TP: 469.6, TN: 688.8, FP: 179.6, FN: 184.6, Prc: 0.723, Rec. 0.718, F1: 0.721\n",
      "Training: [Tot.: 4.418s, Avg.: 0.884s], Validation: [Tot.: 3.803s, Avg.: 0.761s]\n",
      "Order 10 results: Total: 1522.6, TP: 465.4, TN: 673.6, FP: 194.8, FN: 188.8, Prc: 0.705, Rec. 0.711, F1: 0.708\n",
      "Training: [Tot.: 5.342s, Avg.: 1.068s], Validation: [Tot.: 4.055s, Avg.: 0.811s]\n",
      "Order 11 results: Total: 1522.6, TP: 460.2, TN: 662.6, FP: 205.8, FN: 194.0, Prc: 0.691, Rec. 0.703, F1: 0.697\n",
      "Training: [Tot.: 5.690s, Avg.: 1.138s], Validation: [Tot.: 4.171s, Avg.: 0.834s]\n",
      "Order 12 results: Total: 1522.6, TP: 454.4, TN: 656.8, FP: 211.6, FN: 199.8, Prc: 0.682, Rec. 0.695, F1: 0.688\n",
      "Training: [Tot.: 6.598s, Avg.: 1.320s], Validation: [Tot.: 4.329s, Avg.: 0.866s]\n",
      "Order 13 results: Total: 1522.6, TP: 447.2, TN: 658.6, FP: 209.8, FN: 207.0, Prc: 0.681, Rec. 0.684, F1: 0.682\n",
      "Training: [Tot.: 7.318s, Avg.: 1.464s], Validation: [Tot.: 4.455s, Avg.: 0.891s]\n",
      "Order 14 results: Total: 1522.6, TP: 436.0, TN: 661.2, FP: 207.2, FN: 218.2, Prc: 0.678, Rec. 0.666, F1: 0.672\n",
      "Training: [Tot.: 9.179s, Avg.: 1.836s], Validation: [Tot.: 4.705s, Avg.: 0.941s]\n",
      "Order 15 results: Total: 1522.6, TP: 431.8, TN: 665.6, FP: 202.8, FN: 222.4, Prc: 0.680, Rec. 0.660, F1: 0.670\n",
      "Training: [Tot.: 10.275s, Avg.: 2.055s], Validation: [Tot.: 5.075s, Avg.: 1.015s]\n",
      "Best order character based: (6, 0.7366694011484825)\n"
     ]
    }
   ],
   "source": [
    "NUM_SETS = 5\n",
    "\n",
    "print(f'Best order word based: {test_orders(df_train, NUM_SETS, get_wordlist, order_max=6, vocab_size=200, print_results=True)}')\n",
    "print(f'Best order character based: {test_orders(df_train, NUM_SETS, print_results=True)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order 0 Markov Model of 3271 sequences built in 0.058 seconds!\n",
      "Order 0 Markov Model of 4342 sequences built in 0.045 seconds!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         0     NaN      NaN   \n",
       "1         2     NaN      NaN   \n",
       "2         3     NaN      NaN   \n",
       "3         9     NaN      NaN   \n",
       "4        11     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0                    Just happened a terrible car crash       1  \n",
       "1     Heard about #earthquake is different cities, s...       1  \n",
       "2     there is a forest fire at spot pond, geese are...       1  \n",
       "3              Apocalypse lighting. #Spokane #wildfires       1  \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan       1  \n",
       "...                                                 ...     ...  \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...       1  \n",
       "3259  Storm in RI worse than last hurricane. My city...       1  \n",
       "3260  Green Line derailment in Chicago http://t.co/U...       1  \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...       1  \n",
       "3262  #CityofCalgary has activated its Municipal Eme...       1  \n",
       "\n",
       "[3263 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1444\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(PATH_DATA_TEST)\n",
    "\n",
    "classifier = MarkovClassifier(0, get_instances(df_train, 1, get_wordlist), get_instances(df_train, 0, get_wordlist), verbose=True)\n",
    "df_test['target'] = df_test['text'].apply(lambda seq: classifier.predict(get_wordlist(seq))).astype(int)\n",
    "\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_submission = df_test[['id', 'target']]\n",
    "display(df_submission)\n",
    "df_submission.to_csv(os.path.join(DIR_DATA, 'submission.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "array = [1, 4, 2, 20, 18, -4]\n",
    "\n",
    "print(max((v, i) for i, v in enumerate(array))[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
